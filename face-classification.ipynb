{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-15T07:13:39.902849Z",
     "start_time": "2018-03-15T07:13:39.900631Z"
    }
   },
   "source": [
    "# 少ないデータで転移学習を用いて画像内の表情を感情で分類する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018.03.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Flatten, Input, Activation, add\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# 学習済みネットワーク\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの読み込み\n",
    "ディレクトリ構成は下記の通り   \n",
    "各クラス(happy/neutral/angry)30枚の画像を、   \n",
    "学習(train)20枚/バリデーション(validation)5枚/予測(test)5枚に分割\n",
    "\n",
    "`dataset`   \n",
    "`├── train`    \n",
    "`│   ├── happy`   \n",
    "`│   ├── neutral `  \n",
    "`│   └── angry`    \n",
    "`├── validation`   \n",
    "`│   ├── happy `  \n",
    "`│   ├── neutral`   \n",
    "`│   └── angry`    \n",
    "`└── test`   \n",
    "`│   ├── happy `  \n",
    "`│   ├── neutral`   \n",
    "`│   └── angry` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T04:48:22.344888Z",
     "start_time": "2018-03-19T04:48:22.334966Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分類\n",
    "emotions = ['happy', 'neutral', 'angry'] # 分類したい項目名（ディレクトリ名）\n",
    "emotion_count = len(emotions)\n",
    "\n",
    "image_width, image_height = 150, 150\n",
    "\n",
    "# datasetディレクトリ\n",
    "dataset_path = '(データセットのパスを指定)'\n",
    "\n",
    "train_data_path = str(dataset_path) + '/train' \n",
    "validation_data_path = str(dataset_path) + '/validation' \n",
    "test_data_path = str(dataset_path) + '/test' \n",
    "\n",
    "# 重みデータを保存するディレクトリ\n",
    "result_dir = '(重みデータの保存先パスを指定）'\n",
    "\n",
    "# データの枚数\n",
    "train_data_count = 20\n",
    "validation_data_count = 5\n",
    "\n",
    "# バッチサイズ、エポック数\n",
    "batch_size = 16\n",
    "epoch_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの生成（ジェネレータ） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ生成\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.39,\n",
    "    horizontal_flip=True,\n",
    "    samplewise_center=False,\n",
    "    samplewise_std_normalization =False,\n",
    "    zca_whitening=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "generator_train = datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(image_width, image_height),\n",
    "    color_mode='rgb',\n",
    "    classes=emotions,\n",
    "    class_mode='categorical', \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "generator_validation = datagen.flow_from_directory(\n",
    "    validation_data_path, \n",
    "    target_size=(image_width, image_height),\n",
    "    color_mode='rgb',\n",
    "    classes=emotions,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの読み込みと全結合層の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T09:02:20.269976Z",
     "start_time": "2018-03-19T09:02:20.239869Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG16学習済みモデルの読み込み(RGB)\n",
    "input_tensor = Input(shape=(image_width, image_height, 3))\n",
    "learned_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# 全結合層の作成\n",
    "full_model = Sequential()\n",
    "full_model.add(Flatten(input_shape=learned_model.output_shape[1:]))\n",
    "full_model.add(Dense(256, activation='relu',\n",
    "                    kernel_initializer='he_normal'))\n",
    "full_model.add(Dense(64, activation='relu',\n",
    "                    kernel_initializer='he_normal'))\n",
    "full_model.add(Dense(emotion_count, activation='softmax'))\n",
    "\n",
    "# 学習済みデータと全結合層を結合\n",
    "model = Model(inputs=learned_model.input, outputs=full_model(learned_model.output))\n",
    "\n",
    "# 全結合層直前までの層を学習しないようにする\n",
    "for layer in learned_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 学習処理の設定\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T03:57:30.239005Z",
     "start_time": "2018-03-20T03:57:30.175602Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "result = model.fit_generator(\n",
    "    generator_train,\n",
    "    steps_per_epoch=train_data_count,\n",
    "    epochs=epoch_count,\n",
    "    validation_data=generator_validation,\n",
    "    validation_steps=validation_data_count)\n",
    "\n",
    "# 重みを保存\n",
    "model.save_weights(os.path.join(result_dir, 'weight.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習結果の描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "# subplot\n",
    "# loss\n",
    "sub_loss = fig.add_subplot(1,2,1)\n",
    "sub_loss.plot(result.history['loss'])\n",
    "sub_loss.plot(result.history['val_loss'])\n",
    "sub_loss.set_title('model loss')\n",
    "sub_loss.set_ylabel('loss')\n",
    "sub_loss.set_xlabel('epoch')\n",
    "sub_loss.legend(['train', 'verify'], loc='upper left')\n",
    "\n",
    "#Accuracy\n",
    "sub_acc = fig.add_subplot(1,2,2)\n",
    "sub_acc.plot(result.history['acc'])\n",
    "sub_acc.plot(result.history['val_acc'])\n",
    "sub_acc.set_title('model accuracy')\n",
    "sub_acc.set_ylabel('accuracy')\n",
    "sub_acc.set_xlabel('epoch')\n",
    "sub_acc.legend(['train', 'verify'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト画像の予測関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(filepath_list):\n",
    "\n",
    "    for i in filepath_list:\n",
    "        # 画像を読み込んで4次元テンソルへ変換\n",
    "        img = image.load_img(i, target_size=(image_height, image_width))\n",
    "        xarray = image.img_to_array(img)\n",
    "        x = np.expand_dims(xarray, axis=0)\n",
    "        # テストデータも正規化\n",
    "        x = x / 255.0\n",
    "\n",
    "        # 予測 入力は1枚の画像なので[0]のみ\n",
    "        pred = model.predict(x)[0]\n",
    "        \n",
    "        # 描画　topの数だけ予測確率が高い結果を出力\n",
    "        fig = plt.figure(figsize=(2,2))\n",
    "        top = 3\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [(emotions[i], pred[i]) for i in top_indices]\n",
    "        [print(x) for x in result]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in emotions:\n",
    "    print('\\n\\n<<'+ str(x).upper() + '>>\\n')\n",
    "    filepath_list = glob.glob(str(test_data_path)  + '/' + str(x) + '/*')\n",
    "    test_predict(filepath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
